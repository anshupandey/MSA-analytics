{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/MSA-analytics/blob/main/Model_Monitoring/Lab4_Model_Retraining_Strategies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15b0d651",
      "metadata": {
        "id": "15b0d651"
      },
      "source": [
        "# Lab 4: Model Retraining Strategies\n",
        "**Objective**: Learn strategies for retraining models in response to detected drift or performance degradation.\n",
        "\n",
        "This lab will help us understand when and how to retrain models, build retraining pipelines, and assess improvements."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab21e65d",
      "metadata": {
        "id": "ab21e65d"
      },
      "source": [
        "## Step 1: Criteria for Model Retraining\n",
        "- PSI > 0.2 for one or more features\n",
        "- Drop in model performance (e.g., F1-Score < threshold)\n",
        "- Time-based schedule (e.g., monthly retrain)\n",
        "- Significant increase in prediction errors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa2e38a2",
      "metadata": {
        "id": "aa2e38a2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/anshupandey/MSA-analytics/refs/heads/main/datasets/Ocean_Hull_Insurance_datasetv2.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5386b45",
      "metadata": {
        "id": "b5386b45"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X = df.drop('Claim_Occurred', axis=1)\n",
        "y = df['Claim_Occurred']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numeric_features),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a02a51",
      "metadata": {
        "id": "33a02a51"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(\"Before Retraining:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1-Score:\", f1_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad10daf5",
      "metadata": {
        "id": "ad10daf5"
      },
      "source": [
        "## Step 2: Retraining with Updated Dataset\n",
        "We simulate new data arriving over time and use it for retraining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "812738d8",
      "metadata": {
        "id": "812738d8"
      },
      "outputs": [],
      "source": [
        "# Simulate new data (using the test set here)\n",
        "X_new = X_test.copy()\n",
        "y_new = y_test.copy()\n",
        "\n",
        "# Retrain the model\n",
        "pipeline.fit(X_new, y_new)\n",
        "\n",
        "# Evaluate after retraining\n",
        "y_pred_new = pipeline.predict(X_new)\n",
        "print(\"After Retraining:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_new, y_pred_new))\n",
        "print(\"Precision:\", precision_score(y_new, y_pred_new))\n",
        "print(\"Recall:\", recall_score(y_new, y_pred_new))\n",
        "print(\"F1-Score:\", f1_score(y_new, y_pred_new))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}